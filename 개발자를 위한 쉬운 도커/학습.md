# 섹션 0 - 강의 준비

## 실행중인 컨테이너 모두 삭제 하는 방법

### 맥

`docker rm -f $(docker ps -aq)`

### 윈도우

powerShell

`docker ps -aq | ForEach-Object {docker rm -f $_}`

# 섹션 1 - 가상화 기술

## 파트 소개

도커 : 컨테이너 관리를 위한 SW

컨테이너 : 큰 서버를 효율적으로 나누어 사용하기 위한 가상화 기술

서버 - 가상화는 무엇??

Hypervisor vs Container

## 애플리케이션 서버

1. 베어메탈 : 컴퓨터를 구입하고 실행하는 방식(서버 구입 -> OS 설치 -> 소프트웨어 실행)

기업에서 사용하기 비효율적

2. 하이퍼바이저

3. 컨테이너

도커의 방식

## 가상 기술과 하이퍼바이저 가상화 기술

하이퍼바이저는 통역 역할

Guest -> Host 호출할 때 번역하는 역할

- 이 기종 커널 간 요청을 전달
- 가상머신 리소스 할당량 관리

VMware 또는 VirtualBox 등

Kernal이 분리되어 있다(Geust Kernal, Host Kernal)

## 컨테이너 가상화

하이퍼바이저 방식보다 더 선호된다

가볍고 빠르다

커널의 기능으로 자체 격리 환경 조성

LXC(LinuX Containers) 기술

모든 컨테이너는 Host Kernal을 공유한다

하이퍼바이저 방식보다 오버헤드가 더 적다(하드웨어 리소스 사용이 효율적, 속도가 빠름)

Kernal이 독립적인 가상 머신이 보안은 더 뛰어나다

컨테이너는 Host와 동일한 종류의 OS만 실행 가능하다

Docker는 이런 컨테이너를 쉽게 사용할 수 있도록 만들어준다

## Docker

Docker => 컨테이너 플랫폼

컨테이너 플랫폼 = 컨테이너 엔전 + 컨테이너 런타임

### 컨테이너 엔진

사용자 요청을 통해 컨테이너 관리

### 컨테이너 런타임

직접 커널과 통신, 격리된 공간 생성

Docker는 RunC라는 컨테이너 런타임 사용

OCI에서 제정한 CRI 표준 구현

### 아키텍처

클라이언트 - 서버 모델로 사용

클라이언트 -> Docker Deamon(컨테이너 관리)

Docker Deamon은 사용자에게 API 제공

Docker CLI를 통해 API 대신 명령어로 입력할 수 있음

## 컨테이너 실행

### 생성

`docker run -p 80:80 --name hellonginx nginx`

- docker run: 실행
- 80:80: 포트
- hellonginx: 컨테이너 이름
- nginx: 이미지

`Ctrl + c` 로 나올 수 있음

### 삭제

`docker rm hellonginx`

- docker rm : 삭제
- hellonginx : 컨테이너 이름

### 실행 순서도

1. docker run ... nginx

Clinet PC : Host OS

Docker CLI가 명령어를 컨테이너 실행 API로 맞게 만들어 `Docker Deamon`으로 전송

`Docker Deamon`은 요청 분석 후 컨테이너 런타임을 통해 컨테이너 생성

격리된 공간에서 안전한 운영 가능

# 섹션 2 - 이미지와 컨테이너

## 이미지와 컨테이너

`docker image ls`

이미지 목록 보기

`docker image ls ${name}`

name 이름을 가진 이미지 보기

Tag: 버전

Image Id: Image 고유 ID

한 개의 이미지에서 여러개의 컨테이너를 실행할 수 있다

동일한 이미지에서 실행된 컨테이너는 동일한 프로세스로 실행된다

이미지인 상태는 디스크 공간만 차지, 이미지를 컨테이너로 실행해야 CPU, MEMORY를 사용

- 프로세스와의 차이?: 컨테이너라는 격리된 공간이 생성된다

### 하나의 이미지에서 여러개의 컨테이너 실행

`docker run -d --name ${컨테이너 명} ${이미지 명}`

-d: 백그라운드에서 실행

`docker rm -f ${컨테이너 명}`

실행중인 컨테이너는 -f 옵션으로 삭제

## 이미지의 메타데이터

`docker iamge inspect ${이미지 명}` 이미지 메타데이터 조회

`docker container inspect ${이미지 명}` 컨테이너 메타데이터 조회

`docker run ${이미지 명} (${실행 명령})` 컨테이너 실행 시 메타데이터 cmd 덮어 쓰기

`docker run --env KEY=VALUE ${이미지 명}` 컨테이너 실행 시 메타데이터 env 덮어쓰기

## 컨테이너의 라이프사이클

터미널에 `docker create --name tencounter devwikirepo/tencounter`

명령어를 통해 10초 뒤에 종료되는 프로그램을 생성하고

`docker start tencounter`를 수행해 본다

`docker start -i tencounter`를 수행하면 로그가 출력된다

10초 뒤에 `docker ps -a`를 수행해보면 Exited(0)이 되어있다

### HundredCounter

100까지 출력하는 컨테이너를 실행하는데, run으로 해본다

`docker run --name hundredcounter devwikirepo/hundredcounter`

컨테이너 생성과 출력을 같이 한다

이 상태에서 `docker puase hundredcounter`를 입력하면, 작동이 중지되는데, 메모리는 계속 사용중인 상태로 멈춘다

`docker stop hundredcounter`를 수행하면 10초 뒤에 컨테이너를 종료한다

`docker start -i hundredcounter` 명령어를 사용하며, -i 명령어를 사용하면 터미널로 연결된다

이 때 처음부터 수행한다

`docker restart hundredcounter` 명령어를 실행하면 10초 뒤 처음부터 다시 시작한다

이 때는 Exited 되지 않고, Run 상태로 남는다

`docker logs hundredcounter`를 실행하면 1회성의 로그를 출력해준다

이걸 지속하고싶으면 -f 옵션을 추가하여 `docker logs -f hundredcounter`를 입력한다

Ctrl + c로 탈출 가능

# 섹션3 - 이미지 레지스트리

## 이미지 레지스트리

GitHub는 소스코드 공유하는 곳

이미지 레지스트리도 깃허브같은 것

Docker Hub도 이미지 저장하는 곳

이미 저장 공간은 3가지

- 로컬 스토리지(호스트)

- 온라인 스토리지(프라이빗 레지스트리, 퍼블릭 레지스트리)

`docker run nginx`를 수행하면?

먼저 로컬 스토리지에 이미지가 있는지 검색한다 -> 도커를 실행하는 호스트의 특정 폴더

로컬 스토리지에 없으면, 외부에서 이미지 다운로드 받고 실행

다음부터는 로컬 스토리지에서 해당 이미지 실행

도커 허브는 퍼블릭 레지스트리

사내용은 프라이빗 레지스트리

개인만의 레지스트리 사용 방법은 두 가지 있음

- 서버에 레지스트리 설치해서 사용

  - HARBOR
  - DOCKER Private

- 퍼블릭 클라우드의 서비스 사용
  - Amazon ECR
  - Azure Container Registry

### 이미지 네이밍 규칙

`docker run -d -p 80:80 --name hellonginx nginx`

nginx만 쓸 수 있는 이유는 default 값이 있기 때문이다

원래는 모든 정보를 써줘야한다

레지스트리 주소/프로젝트 명/이미지 명:이미지 태그

레지스트리 주소: 어떤 레지스트리를 사용할지 지정, 비어있는 경우 기본값으로 설정된 것이 사용됨

docker를 사용하면? docker hub 주소인 `docker.io`

개인 registry 주소를 사용하려면, `montag.com/` 이런 방법으로 사용해야 함

아무것도 안적으면 `docker.io`가 기본값

docker hub는 가입 사용자 명이 프로젝트 명

프로젝트 명은 다운로드 받을 이미지 이름(이거 생략하면 도커 오피셜 이미지인 library에서 가져옴)

이미지 태그는 이미지 버전(빈 값이면 :latest가 기본값)

`devwikirepo/hundredcounter` 이건 풀로쓰면

`docker.io/devwikirepo/tencounter:latest`

`nginx`는 곧 `docker.io/library/nginx:latest`이다

## 이미지 레지스트리 실습

로컬 스토리지로 이미지 다운로드</br>
`docker pull ${이미지명}`

새로운 이미지명을 만드는 명령어</br>
`docker tag ${기존이미지명} ${추가할이미지명}`

이미지 레지스트리에 이미지 업로드</br>
`docker push ${이미지명}`

docker tag로 이름 바꾸면 이미지 아이디가 같다

### 로그인

`docker login`</br>
이미지 레지스트리 인증 정보 생성

`docker logout`</br>
이미지 레지스트리 인증 정보 삭제

`docker image rm 이미지명`</br>
로컬 스토리지의 이미지 삭제

나는 도커 데스크탑으로 로그인해놔서 따로 인증 절차를 거치지 않았다

`cat ~/.docker/config.json` 명령으로 인증 정보를 확인할 수 있는데,

```bash
{
        "auths": {},
        "credsStore": "desktop",
        "currentContext": "default",
        "plugins": {
                "-x-cli-hints": {
                        "enabled": "true"
                }
        }
}
```

이렇게 빈 칸이 나온다, 아마 login 명령을 치지 않아서 auths에 정보가 안들어간 것 같다

하지만 pull, push는 잘 작동한다

똑같은 이미지 아이디를 가진 파일중 하나를 삭제하면, 그냥 `Untagged`로 끝난다

하지만 나머지 파일도 삭제하면, 실제로 파일을 제거하는 `Delete`까지 수행한다

`docker run -d -p 80:80 --name my-simple-web yuseop/my-simple-web:0.1`

이 명령으로 컨테이너를 생성

도커 이미지 파일을 사용하면, 각각의 다른 운영 환경을 통일할 수 있다

# 섹션 4 - 이미지 빌드

## 이미지와 레이어

도커 이미지? 컨테이너를 실행하기 위한 읽기 전용 파일(Layered file system)

재사용하기 유리한 레이어드 구조

기존 레이어에서 추가된 부분만 저장한다

같은 부분은 공유 - 재사용

이미지 레이어는 읽기 전용이고, 컨테이너 레이어만 읽고 쓸 수 있다

같은 이미지에서 왔어도, 수정 순서가 다르면 다른 해시값으로 저장된다

Layering: 각 레이어는 이전 레이어 위에 쌓이며, 여러 이미지 간에 공유될 수 있음. </br>
중복 데이터를 최소화하고 빌드 속도를 높이며, 저장소를 효율적으로 사용

Copy-on-Write(CoW) 전략: 다음 레이어에서 이전 레이어의 특정 파일을 수정할 때, </br>
해당 파일의 복사본을 만들어 변경 사항을 적용. 원래 레이어는 수정되지 않고 유지

Immutable Layers(불변 레이어): 이미지 각 레이어는 불변으로, 한번 생성되면 변하지 않음</br>
CoW 전략의 이유. 이미지의 일관성을 유지하고, 여러 컨테이너에서 안전하게 공유

Caching(캐싱): 레이어를 캐시하여 이미 빌드된 레이어를 재사용</br>
이미지 빌드 시간을 줄이고, 같은 레이어를 사용하는 여러 이미지에서 효율적

## 이미지 커밋

이미지를 만드는 방법에는 커밋과 빌드가 있다

실행중인 컨테이너를 그대로 이미지로 만드는 커밋

`docker run -it --name ${컨테이너명} ${이미지명} bin/bash`

컨테이너 실행과 동시에 터미널 접속하는 명령어

`docker commit -m ${커밋명} ${실행중인컨테이너명} ${생성할이미지명}`

officialNginx를 이미지로 커밋하기

`docker run -d -p 80:80 --name my-nginx yuseop/commitnginx` 명령으로 실행

## 이미지 빌드

빌드는 도커파일 명세서를 통해 이미지 생성

### IaC(Infrastructure as Code)

인프라 상태를 코드로 관리하는 방법론, 도커도 이 방식을 사용한다

도커의 코드로 이미지를 관리하는 방식이 빌드

### 커밋과 빌드의 비교

커밋 방식의 문제점

- 이미지를 만들 때 마다 컨테이너 실행
- 사용자가 직접 명령어 입력
- 커밋 하나에 이미지 레이어 1개라, 여러개 추가하려면 커밋 여러번

그래서 커밋보다 빌드 방식을 많이 사용한다

컨테이너 생성 및 커밋을 도커가 대신 수행

도커가 어떤 작업을 할 것인가를 도커파일로 만들어서 실행

`docker build -t ${이미지명} ${Dockerfile경로}`

도커파일의 명령어는 지시어와 지시어의 옵션으로 구성

```dockerfile
FROM ${이미지명}
COPY ${파일경로} ${복사할경로}
CMD ["명령어"]
```

FROM: 베이스 이미지 지정</br>
COPY: 파일을 레이어에 복사</br>
CMD["명령어"]: 컨테이너 실행시 명령어 지정

## 빌드 컨텍스트

실습

## 도커 파일 지시어

애플리케이션 빌드: 소스코드를 실행 가능한 프로그램으로 빌드(애플리케이션, 프로그램, 아티팩트 등을 생성)

도커 빌드: 도커파일을 이미지로 빌드(중간에 애플리케이션 빌드도 포함함)

실습 진행

`WORKDIR ${폴더명}`: 작업 디렉토리 지정(cd 명령과 유사)

`USER ${유저명}`: 명령을 실행할 사용자 변경 (기본은 root인데, 보안에 취약할 수 있음)

`EXPOSE ${포트번호}`: 컨테이너가 사용할 포트 명시

환경 변수

`ARG ${변수명} ${변수값}`: 이미지 빌드 시점의 환경 변수 설정

`ENV ${변수명} ${변수값}`: 이미지 빌드 및 컨테이너 실행 시점의 환경 변수 설정

무슨 차이?

컨테이너 실행할 때 환경변수가 유지되는가?

ARG는 build 명령어로 빌드할 때만</br>
`docker build --build-arg ${변수명}=${변수값}`으로 덮어쓰기 가능

ENV는 실행까지 유지
`docker run -e ${변수명}=${변수값}`

설정하고 실행해보면, ARG는 RED컬러로 환경변수를 설정해도 실제로는 초록색이 나온다...

`ENTRYPOINT["${명령어}"]`: 고정된 명령어를 지정 -> 중복된 명령어 관리

`CMD["${명령어}"]` 실행할 때 명령어 지정

ENTRYPOINT에 npm 등록, CMD에 start 등록하면 start만 쳐도 npm start 실행

## 멀티 스테이지 빌드

도커 파일에서 두 개의 베이스 이미지를 활용하는 것

단일 스테이지 빌드에서 용량이 741MB인 것이</br>
멀티 스테이지 빌드에서는 241MB로 확 줄어들었다

빌드에만 필요한 메이븐 이미지를 멀티 스테이지에서는 사용하지 않음

# 섹션 5 - 컨테이너 애플리케이션 구성

## 클라우드 네이티브(Cloud Native) 애플리케이션

클라우드는 보통 스토리지 저장소를 의미한다

물리적 디바이스로부터 자유로워지고, 확장이 용이

다른 회사 서버를 빌려서 운영하며, 누구나 사용 가능한 퍼블릭, 특정 조직만 사용할 수 있는 프라이빗이 있다

요청 즉시 서버생성(Provisioning - 프로비저닝)

실제 사용 시간만큼 비용 지불

- 트래픽이 증가할 때 빠르게 대처할 수 있는가?(확장성, Scalability)</br>
  온프레미스에서는 서버가 준비되있지 않은 경우 새로운 서버 증가에 오랜 시간이 소요</br>
  클라우드에서는 서버 추가가 10분 내로 빠르게 이루어진다
- 장애 발생시 빠르게 복구할 수 있는가?(복원력, Resilience)</br>
  클라우드 환경에서는 백업 및 복구가 빠르게 이루어질 수 있음(Disaster Recovery)
- 운영 비용을 효율적으로 운영할 수 있는가?</br>
  사용한 만큼 지불할 수 있기 때문에 운영 비용에 더 효율적

### 클라우드 네이티브?

클라우드 환경을 더 잘 활용할 수 있는 애플리케이션 구조

1. MSA: 트래픽 증가에 빠르게 대처하기 위해서 MSA구조로 개발되어야 합니다(애플리케이션을 여러 단위로 분할하여 트래픽 증가에 대처)

2. 컨테이너: 컨테이너를 활용해 실행 환경에 종속되지 않는 동작이 보장(어떤 환경에서든 동일한 실행환경 보장)

3. 무상태(Stateless): 애플리케이션 서버는 상태를 가지지 않아야 한다. 상태를 가지는 것은 각각 서버가 다르게 운영될 수 있음을 의미

4. DevOps 및 CI/CD: 배포 자동화 및 빠른 릴리즈 필요

### MSA?

하나의 애플리케이션에 모든 기능을 구현하는 모놀리식(Monolithic) 방식의 단점 보완

- 서버 증가시 전체 기능을 늘려야 함
- 하나의 서버가 모든 트래픽 수용
- 개발 빌드 시간, 배포 시간이 오래 걸림
- 일부 기능만 업데이트 해도, 다른 기능이 영향을 받아 리소스의 낭비가 생김

## Leafy 애플리케이션 구성

`docker network create leafy-network` 명령어로 네트워크를 생성

`docker run -d --name leafy-postgres --network leafy-network devwikirepo/leafy-postgres:1.0.0` 명령어로 postgres 이미지 받아오기

나머지도 명령어를 통해 가져오는데, network로 다 연결해준다

도커는 기본적으로 각각의 격리된 컨테이너라 상호 통신이 안된다

따라서 bridge를 연결하기 위한 명령어가 network이다

이 명령어를 통해 동일 네트워크 내의 도커 컨테이너들이 상호 통신을 할 수 있다

그렇다면 하둡 서버를 도커로 구성하는게 더 쉽지 않을까 싶은 생각이 들었다

## postgreSQL 컨테이너 구성

실습

## SpringBoot 백엔드 컨테이너 구성

실습

## Vue.js 프론트엔드 컨테이너 구성

실습
